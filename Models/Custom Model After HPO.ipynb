{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Custom Model After HPO.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"61jFkqTQ53Yu","colab_type":"text"},"source":["In this notebook the custom model is trained with the best parameters from the HPO."]},{"cell_type":"code","metadata":{"id":"NAAvc8iXf8ta","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1592555430973,"user_tz":-120,"elapsed":3176,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"4f584f36-7e65-487e-c31f-e78bb6fe7b9e"},"source":["#Tensorflow Import and GPU recognition\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r6IM-pcYffa3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":461},"executionInfo":{"status":"ok","timestamp":1592555430974,"user_tz":-120,"elapsed":3162,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"a4e6b51d-de30-4d4f-9420-4ee9cef81253"},"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 8988885223254764391, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 16305806687984993003\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 3016545379236591008\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 11150726272\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 13506356169886679055\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"ne-yITM399RK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1592555432199,"user_tz":-120,"elapsed":4361,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"c41ed818-8d86-4342-cfe2-0993c3e4d32b"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m-Lph1dVGDQj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":49},"executionInfo":{"status":"ok","timestamp":1592555440811,"user_tz":-120,"elapsed":12957,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"391f0175-3c57-4f39-a13f-b9b15b210267"},"source":["!unzip '/content/drive/My Drive/Progetto Advanced Machine Learning/fruits.zip' -d '/content'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Archive:  /content/drive/My Drive/Progetto Advanced Machine Learning/fruits.zip\n","replace /content/fruits-360_dataset/fruits-360/LICENSE? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YQBGXs87jba3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592555440813,"user_tz":-120,"elapsed":12948,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["# importing some useful libs\n","import os\n","from os import listdir, makedirs\n","from os.path import join, exists, expanduser\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from glob import glob\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"onB9L-fAuOmy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1592555440813,"user_tz":-120,"elapsed":12940,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"90e3aa69-87f5-4726-f9f4-b129842a43c6"},"source":["#Defining dataset path and saving it for future usage\n","path = '/content/fruits-360_dataset/fruits-360'\n","os.listdir(path)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Training', 'LICENSE', 'Test', 'papers', 'readme.md', 'test-multiple_fruits']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"w9VyHRkNvJf3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1592555440814,"user_tz":-120,"elapsed":12929,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"a9b30db5-a948-4284-898c-2f4f5e5a5eaf"},"source":["#Number of pictures in Training folder\n","training_files = glob(os.path.join(path,'Training', '*/*.jpg'))\n","image_num = len(training_files)\n","print(\"Number of Images: \",image_num)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Number of Images:  60498\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fsGZKGH9yM7l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1592555440814,"user_tz":-120,"elapsed":12918,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"af7db357-1f6d-4814-e7b8-d4437a0f7aa4"},"source":["#Number of pictures in Test Folder\n","testing_files = glob(os.path.join(path, 'Test', '*/*.jpg'))\n","img_num = len(testing_files)\n","print(\"Number of Images: \", img_num)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Number of Images:  20622\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HAgu-_E-yrRe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592555440815,"user_tz":-120,"elapsed":12907,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"20344b84-de94-477d-aa4f-8b6ef765f343"},"source":["#Print category details\n","image_count = []\n","class_names = []\n","print('{:18s}'.format('Class'), end='')\n","print('Count:')\n","print('-'*24)\n","for folder in os.listdir(os.path.join(path,'Training')):\n","  folder_count = len(os.listdir(os.path.join(path,'Training',folder)))\n","  image_count.append(folder_count)\n","  class_names.append(folder)\n","  print('{:20s}'.format(folder), end='')\n","  print(folder_count)\n","print('-'*24)\n","print('Number of Classes:', len(class_names))\n","print('Average number of images per Class: ', np.array(image_count).mean())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Class             Count:\n","------------------------\n","Pear Abate          490\n","Nectarine           492\n","Apple Golden 3      481\n","Pear Forelle        702\n","Tomato Maroon       367\n","Pepper Green        444\n","Tomato 4            479\n","Apple Red Yellow 2  672\n","Tangelo             490\n","Potato Red Washed   453\n","Physalis with Husk  492\n","Carambula           490\n","Walnut              735\n","Pepino              490\n","Pear Kaiser         300\n","Apple Red 1         492\n","Kumquats            490\n","Mulberry            492\n","Mango Red           426\n","Plum 3              900\n","Melon Piel de Sapo  738\n","Peach Flat          492\n","Peach 2             738\n","Cauliflower         702\n","Orange              479\n","Kohlrabi            471\n","Grapefruit White    492\n","Cherry Wax Yellow   492\n","Cantaloupe 2        492\n","Apple Golden 1      492\n","Apple Crimson Snow  444\n","Grape White         490\n","Pepper Red          666\n","Huckleberry         490\n","Potato Red          450\n","Pomelo Sweetie      450\n","Kaki                490\n","Nut Pecan           178\n","Tomato 2            672\n","Quince              490\n","Apple Red 3         429\n","Pear                492\n","Cherry Wax Black    492\n","Apple Granny Smith  492\n","Clementine          490\n","Maracuja            490\n","Nectarine Flat      480\n","Blueberry           462\n","Grape Blue          984\n","Raspberry           490\n","Papaya              492\n","Grape White 2       490\n","Pineapple           490\n","Eggplant            468\n","Potato White        450\n","Mangostan           300\n","Pear Williams       490\n","Grape White 4       471\n","Grape White 3       492\n","Lychee              490\n","Guava               490\n","Passion Fruit       490\n","Pepper Yellow       666\n","Peach               492\n","Banana Lady Finger  450\n","Grape Pink          492\n","Mandarine           490\n","Avocado ripe        491\n","Cactus fruit        490\n","Lemon Meyer         490\n","Banana Red          490\n","Cherry Wax Red      492\n","Apple Red 2         492\n","Granadilla          490\n","Apple Red Yellow 1  492\n","Pineapple Mini      493\n","Dates               490\n","Rambutan            492\n","Salak               490\n","Avocado             427\n","Nut Forest          218\n","Mango               490\n","Apple Braeburn      492\n","Cantaloupe 1        492\n","Apricot             492\n","Cherry Rainier      738\n","Limes               490\n","Onion Red           450\n","Tomato Cherry Red   492\n","Kiwi                466\n","Tomato Yellow       459\n","Apple Golden 2      492\n","Plum 2              420\n","Banana              490\n","Lemon               492\n","Pomegranate         492\n","Tomato 3            738\n","Pear Monster        490\n","Cherry 2            738\n","Pitahaya Red        490\n","Grapefruit Pink     490\n","Apple Red Delicious 490\n","Strawberry          492\n","Ginger Root         99\n","Pear Red            666\n","Beetroot            450\n","Chestnut            450\n","Redcurrant          492\n","Cocos               490\n","Tamarillo           490\n","Apple Pink Lady     456\n","Physalis            492\n","Onion Red Peeled    445\n","Cherry 1            492\n","Tomato 1            738\n","Plum                447\n","Potato Sweet        450\n","Hazelnut            464\n","Onion White         438\n","Strawberry Wedge    738\n","------------------------\n","Number of Classes: 120\n","Average number of images per Class:  504.15\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KRd0d67Dugz1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":49},"executionInfo":{"status":"ok","timestamp":1592555440815,"user_tz":-120,"elapsed":12895,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"c838bf50-906f-45cb-d8f0-9494229ac770"},"source":["#Definitive paths\n","train_out_path = os.path.join(path,'Training')\n","test_out_path = os.path.join(path, 'Test')\n","print(train_out_path)\n","print(test_out_path)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/content/fruits-360_dataset/fruits-360/Training\n","/content/fruits-360_dataset/fruits-360/Test\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TxaJOJtiqOz6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592555440816,"user_tz":-120,"elapsed":12886,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["#Implementing some augmentation to avoid overfitting on the training generator\n","train_datagenerator = ImageDataGenerator(rescale=1. / 255, rotation_range=30, zoom_range=0.2, horizontal_flip=True, validation_split=0.2, data_format='channels_last')\n","train_and_val_generator = ImageDataGenerator(rescale=1. / 255, rotation_range=30, zoom_range=0.2, horizontal_flip=True, data_format='channels_last')\n","test_datagenerator = ImageDataGenerator(rescale= 1./255, data_format='channels_last')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y8RWUCoqrEFy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":82},"executionInfo":{"status":"ok","timestamp":1592555444300,"user_tz":-120,"elapsed":16361,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"b246caeb-bf2e-419c-de0b-b22c6bf8ea55"},"source":["#Creating Batches\n","image_size = (256, 256)\n","train_batches = train_datagenerator.flow_from_directory(train_out_path, target_size=image_size, color_mode=\"rgb\", class_mode=\"categorical\" ,  batch_size=32, subset='training', seed=20052020)\n","val_batches = train_datagenerator.flow_from_directory(directory=train_out_path, target_size=image_size, color_mode=\"rgb\", class_mode=\"categorical\" ,  batch_size=32, subset='validation', shuffle=False, seed=20052020)\n","train_val_batches = train_and_val_generator.flow_from_directory(directory=train_out_path, target_size=image_size, color_mode=\"rgb\", class_mode=\"categorical\" ,  batch_size=32, shuffle=False, seed=20052020)\n","test_batches = test_datagenerator.flow_from_directory(directory=test_out_path, target_size=image_size, color_mode=\"rgb\", class_mode=\"categorical\" ,  batch_size=32, shuffle=False)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Found 48431 images belonging to 120 classes.\n","Found 12067 images belonging to 120 classes.\n","Found 60498 images belonging to 120 classes.\n","Found 20622 images belonging to 120 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BpKOUWq0Atg0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592555476076,"user_tz":-120,"elapsed":622,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["# imports for building the model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalMaxPool2D, Dropout,  Dense\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqo1Epp8rHV2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":345},"executionInfo":{"status":"ok","timestamp":1592555477658,"user_tz":-120,"elapsed":1614,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"998140c0-6a91-41d2-9b47-8c8431b21863"},"source":["#build custom model\n","model = Sequential()\n","model.add( Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding='same', data_format='channels_last', activation='relu', name='conv_1', input_shape=image_size+(3,)))\n","model.add( MaxPool2D(pool_size=(2, 2), strides=1, data_format='channels_last', name='pool_1'))\n","model.add( Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', data_format='channels_last', activation='relu', name='conv_2'))\n","model.add( GlobalMaxPool2D(data_format='channels_last', name='pool_2'))\n","model.add( Dropout(0.08832308429673111))\n","model.add( Dense(120, activation='softmax', name='prediction', kernel_regularizer=l2(0.09116292059447313)))\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0029464233838192235), metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv_1 (Conv2D)              (None, 256, 256, 128)     3584      \n","_________________________________________________________________\n","pool_1 (MaxPooling2D)        (None, 255, 255, 128)     0         \n","_________________________________________________________________\n","conv_2 (Conv2D)              (None, 255, 255, 64)      73792     \n","_________________________________________________________________\n","pool_2 (GlobalMaxPooling2D)  (None, 64)                0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 64)                0         \n","_________________________________________________________________\n","prediction (Dense)           (None, 120)               7800      \n","=================================================================\n","Total params: 85,176\n","Trainable params: 85,176\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Q_TWWkbYo_T","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1592555444301,"user_tz":-120,"elapsed":16339,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["'''\n","model_path = '/content/drive/My Drive/Progetto Advanced Machine Learning/Model Checkpoints/Custom Model 1 2020-06-01 10:56:21.010759.hdf5'\n","model = tf.keras.models.load_model(model_path)\n","x = model.layers[-2].output\n","x = Dropout(0.00032332824201601514)(x)\n","predictions = Dense(120, activation='softmax', name='prediction', kernel_regularizer=l2(0.24718165404756284))(x)\n","model = Model(inputs=model.inputs, outputs=predictions)\n","for layer in model.layers[:-2]:\n","  layer.trainable = False\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0980741228990046), metrics=['accuracy'])\n","\n","model.summary()\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"13h2Poxn12Ry","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"error","timestamp":1592556734120,"user_tz":-120,"elapsed":1251718,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}},"outputId":"10b8318f-73f5-4acb-ec97-213bee3bb401"},"source":["# training the model with early stopping\n","model.save_weights('Initial Weights.hdf5')\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","model.fit(train_batches, epochs=15, verbose=1, shuffle=True, validation_data=val_batches, callbacks=[early_stopping], workers=2)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","1514/1514 [==============================] - ETA: 0s - loss: 3.0970 - accuracy: 0.3237"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-87c09c082eaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initial Weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"kpKtbSQaKJzO","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1592555444303,"user_tz":-120,"elapsed":16331,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["model.load_weights('Initial Weights.hdf5')\n","trainingMdl = model.fit(train_val_batches, epochs=1early_stopping.stopped_epoch, verbose=1, shuffle=True, validation_data=test_batches, workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKSJ-q54U7lT","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1592555444303,"user_tz":-120,"elapsed":16329,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["#plot training history\n","import sys\n","sys.path.append('/content/drive/My Drive/Progetto Advanced Machine Learning/')\n","import utils\n","history_fig = utils.plot_history(trainingMdl)\n","history_fig.set_size\n","history_fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NFqUKCDU2fr","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1592555444303,"user_tz":-120,"elapsed":16328,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["import datetime\n","save_path = '/content/drive/My Drive/Progetto Advanced Machine Learning/Model Checkpoints/'\n","save_path += 'Custom Model 1 After HPO'\n","save_path += str(datetime.datetime.now())\n","model.save(save_path + '.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q2ljNqMVW1G6","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1592555444304,"user_tz":-120,"elapsed":16327,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["#save training history plot\n","!wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n","!chmod +x /usr/local/bin/orca\n","!apt-get install xvfb libgtk2.0-0 libgconf-2-4\n","history_fig.write_image(save_path +'.pdf', format='pdf')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c6CeGBwvek1j","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1592555444304,"user_tz":-120,"elapsed":16326,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["#save training history\n","import pickle\n","with open(save_path +'.history.pickle', 'wb') as f:\n","  pickle.dump(trainingMdl.history, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjPkqxlfnQjr","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1592555444305,"user_tz":-120,"elapsed":16325,"user":{"displayName":"Davide Toniolo","photoUrl":"","userId":"13778737186638760738"}}},"source":["cm = utils.get_confusion_matrix(model, val_batches)\n","fig = utils.plot_cm(cm, class_names)\n","plt.savefig(save_path + '.confusion_matrix.pdf', format='pdf')\n","fig"],"execution_count":null,"outputs":[]}]}